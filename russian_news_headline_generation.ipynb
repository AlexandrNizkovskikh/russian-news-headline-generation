{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "s-UEdYliXUVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qUVRT3pqXlS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Загрузка датасета\n",
        "dataset = load_dataset(\"zloelias/lenta-ru\")\n",
        "\n",
        "train_data = load_dataset(\"zloelias/lenta-ru\", split=\"train\")"
      ],
      "metadata": {
        "id": "Daa76gycXVbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Загрузка данных\n",
        "df = pd.DataFrame(train_data)"
      ],
      "metadata": {
        "id": "305R9kLxX_ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.info())  # Типы данных и наличие пустых значений"
      ],
      "metadata": {
        "id": "NUuR7fjlc589"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.describe(include='all'))  # Основные статистики"
      ],
      "metadata": {
        "id": "JjmaZPhRc7zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "id": "xNkwopibc9EI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df['text_length'] = df['text'].apply(lambda x: len(x.split()))\n",
        "plt.hist(df['text_length'], bins=50)\n",
        "plt.xlabel(\"Длина текста (в словах)\")\n",
        "plt.ylabel(\"Количество текстов\")\n",
        "plt.show()\n",
        "\n",
        "print(df['text_length'].describe())"
      ],
      "metadata": {
        "id": "wclUUqgndl84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['labels'].value_counts())  # Подсчёт по категориям"
      ],
      "metadata": {
        "id": "p5AZk8crd2dC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(subset=['text'], inplace=True)\n",
        "print(f\"Количество строк после удаления дубликатов: {len(df)}\")"
      ],
      "metadata": {
        "id": "vI1gxl67eUNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Удаление слишком коротких текстов (например, менее 10 слов)\n",
        "df_balanced = df_balanced[df_balanced['text'].apply(lambda x: len(x.split()) > 10)]"
      ],
      "metadata": {
        "id": "DRqN5Ch3s9Qr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обрезка текстов до 512 слов\n",
        "max_length = 512\n",
        "df_balanced['text'] = df_balanced['text'].apply(lambda x: ' '.join(x.split()[:max_length]))"
      ],
      "metadata": {
        "id": "Al6YoIYvtC60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "# Создадим выборки для каждой категории\n",
        "df_0 = df[df['labels'] == 0]\n",
        "df_1 = df[df['labels'] == 1]\n",
        "df_2 = df[df['labels'] == 2]\n",
        "df_3 = df[df['labels'] == 3]\n",
        "df_4 = df[df['labels'] == 4]\n",
        "\n",
        "# Уменьшим количество данных для категории 0 до количества данных в категории 4\n",
        "df_0_downsampled = resample(df_0, replace=False, n_samples=5, random_state=42)\n",
        "df_1_downsampled = resample(df_1, replace=False, n_samples=5, random_state=42)\n",
        "df_2_downsampled = resample(df_2, replace=False, n_samples=5, random_state=42)\n",
        "df_3_downsampled = resample(df_3, replace=False, n_samples=5, random_state=42)\n",
        "df_4_downsampled = resample(df_4, replace=False, n_samples=5, random_state=42)\n",
        "df_balanced = pd.concat([df_0_downsampled, df_1_downsampled, df_2_downsampled, df_3_downsampled, df_4_downsampled])\n",
        "\n",
        "print(df_balanced['labels'].value_counts())  # Проверим новое распределение"
      ],
      "metadata": {
        "id": "qbNKGS9Ss8pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Удаляем ненужные столбцы\n",
        "df_final = df_balanced.drop(columns=['title', 'topic', 'text_length', 'labels'])\n",
        "\n",
        "# Проверяем оставшиеся столбцы\n",
        "print(df_final.head(20))"
      ],
      "metadata": {
        "id": "8NbhQAQxuDnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final.to_csv('final_dataset.csv', index=False)"
      ],
      "metadata": {
        "id": "WdZ99ZkFxWd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch\n",
        "DEVICE = torch.device(\"cuda:0\")\n",
        "\n",
        "# Для большей наглядности будем работать с русскоязычной версией GPT от Сбера.\n",
        "# Ниже находятся команды для загрузки и инициализации модели и токенизатора.\n",
        "model_name = \"sberbank-ai/rugpt3medium_based_on_gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name).to(DEVICE)"
      ],
      "metadata": {
        "id": "iECjUS5axb62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
        "\n",
        "train_path = 'final_dataset.csv'\n",
        "\n",
        "# Создание датасета\n",
        "train_dataset = TextDataset(tokenizer=tokenizer, file_path=train_path, block_size=64)\n",
        "\n",
        "# Создание даталодера (нарезает текст на оптимальные по длине куски)\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
      ],
      "metadata": {
        "id": "qIyPNwlIxm0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./finetuned\",       # директория с выходными данными\n",
        "    overwrite_output_dir=True,      # перезаписываем содержимое выходной директории при каждом запуске\n",
        "    num_train_epochs=200,           # число эпох обучения\n",
        "    per_device_train_batch_size=32, # batch size для обучения\n",
        "    per_device_eval_batch_size=32,  # batch size для выполнения\n",
        "    warmup_steps=10,                # количество шагов для \"прогрева\" (управление скоростью обучения)\n",
        "    gradient_accumulation_steps=16, # накопление градиента (16 шагов накапливаем градиенты для batch_size, эмуляция вычисления на пакете 16 * 32 для слабых GPU)\n",
        "    )\n",
        "\n",
        "# Инициализируем класс обучения\n",
        "trainer = Trainer(\n",
        "    model=model,                 # модель\n",
        "    args=training_args,          # параметры обучения\n",
        "    data_collator=data_collator, # загрузчик данных\n",
        "    train_dataset=train_dataset, # датасет для обучения\n",
        "    optimizers = (torch.optim.AdamW(model.parameters(), lr=1e-5), None) # оптимизатор\n",
        ")"
      ],
      "metadata": {
        "id": "-4a2h1Ne0WFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "SHbj1dZ30Xkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\n",
        "    \"В Москве запущен новый проект\",\n",
        "    \"Президент выступил с заявлением\",\n",
        "    \"Ученые открыли новое средство\",\n",
        "    \"Спортсмен побил рекорд\",\n",
        "    \"Технологическая компания анонсировала\",\n",
        "    \"Глобальные изменения климата\",\n",
        "    \"В стране планируется провести\",\n",
        "    \"Новый законопроект был внесен\",\n",
        "    \"Эксперты предсказывают\",\n",
        "    \"Пандемия привела к\"\n",
        "]"
      ],
      "metadata": {
        "id": "kD77VBw9agUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Генерация новостей\n",
        "generated_texts = []\n",
        "\n",
        "for text in texts:\n",
        "    input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\n",
        "    model.eval()\n",
        "    out = model.generate(input_ids, max_length=70)\n",
        "    generated_text = tokenizer.decode(out[0], skip_special_tokens=True)\n",
        "    generated_texts.append(generated_text)\n",
        "    print(f\"Input: {text}\\nGenerated News: {generated_text}\\n{'-'*50}\")"
      ],
      "metadata": {
        "id": "_N4xjOkpa732"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}